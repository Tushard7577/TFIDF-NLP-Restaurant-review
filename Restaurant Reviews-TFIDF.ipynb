{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5faeb252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41532b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/Restaurant_Reviews.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c290ff65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27167017",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4545929a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow... Loved this place.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = reviews.iloc[0]\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd978de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c141717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007b9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499cba39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stemmer.stem('loving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd2f998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow love place'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "r1 = reviews.iloc[0]\n",
    "\n",
    "# 1. all lower\n",
    "r1 = r1.lower()\n",
    "\n",
    "# 2. remove unwanted characters (non alphabets)\n",
    "import re # regular expressions - pattern matching\n",
    "pattern = '[^a-z]'   # identify chars which are not alphabets\n",
    "r1 = re.sub(pattern,' ',r1)\n",
    "\n",
    "# 3. remove stopwords\n",
    "words = r1.split()\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "# 4. stemming/lemmatization\n",
    "words = [stemmer.stem(word) for word in words]\n",
    "' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8129d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(r1):\n",
    "    r1 = r1.lower()\n",
    "    pattern = '[^a-z]'   # identify chars which are not alphabets\n",
    "    r1 = re.sub(pattern,' ',r1)\n",
    "    words = r1.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aaa4662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow love place'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess('Wow... Loved this place.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d0c1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_reviews = reviews.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb23866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOW\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(processed_reviews) # unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ce399e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf710713",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_table = vectorizer.transform(processed_reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15f1aec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1565)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0824ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bulid ML model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(tfidf_table,df['Liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4486a500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf_table,df['Liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad896b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data\n",
    "reviews = ['food was good.','excellent service','good food nice test','The food is really, really good, and the service is super nice.','So pathetic service and food quality','Family friendly hotel with good parking','Beautiful food , lovely service and surrounding.','I had a delightful brunch at The Cozy Cafe. The eggs benedict were perfection, and the atmosphere is charming','The ambiance is superb']\n",
    "reviews = [preprocess(r) for r in reviews]\n",
    "X_test = vectorizer.transform(reviews).toarray()\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9e5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
